ðŸ“ˆ Completion Rate Analysis: UI Design Experiment at Vanguard 

Welcome to the Vanguard Completion Rate Analysis project. This initiative focuses on assessing the impact of a new UI design through a structured A/B testing framework, with the goal of enhancing user engagement and achieving cost-effective improvements.

ðŸ”¬ Experiment Structure:

A/B Testing Framework: The study compared completion rates between test and control groups over a three-month period. This structured approach effectively isolated the effects of the new UI design on user behavior.

Statistical Analysis: Used a two-sample z-test to determine statistical significance in completion rate differences, offering robust evidence for decision-making.

ðŸ“‹ Data Overview:

Data Collection Period: Conducted from March 15 to June 20, 2017, the experiment provided comprehensive data reflecting varied user interaction patterns.

Balanced Sampling: Ensured participants were evenly distributed across test and control groups, enabling valid conclusions about the UI's effect.

ðŸ’¡ Key Findings:

Completion Rate Increase: The test group demonstrated a significant improvement, surpassing the 5% threshold necessary for cost-effectiveness, validating the new UIâ€™s positive impact on user engagement.

Further Insights: To enhance user strategies, future research can focus on demographic interactions with the UI. Analyzing metrics such as time spent per step and error rates can provide valuable insights into design efficacy. Monitoring time on steps can help identify delays, while error tracking can detect areas where regressions occur, targeting potential confusion or errors for improvement.

ðŸ“Š Methodology Details:

Before analysis, data was meticulously prepared to ensure reliability:

Preprocessing: Involved cleaning and verifying data to align with study aims.
Systematic Approach: Applied industry-standard methodologies to assess statistical outcomes confidently.

ðŸ”§ Replication Instructions:

To reproduce the analyses:

Data Preparation: Ensure access to experiment data. Set up the necessary Python environment with libraries such as NumPy, Pandas, and Matplotlib for data analysis. Additionally, prepare Tableau for visualizing analytical results, enabling interactive and comprehensive presentations of key insights.

Analysis Execution: Use the provided scripts to run statistical tests and generate visualizations illustrating completion rate enhancements.

For accessing the large dataset used in this project, please download it from the following link:
- [df_final_web_data_pt_1.csv] (https://drive.google.com/file/d/17Wy5EVg621ecVBhqhQipWXlPB1MExcUv/view?usp=sharing)
- [df_final_web_data_pt_2.csv] (https://drive.google.com/file/d/1C3j2m541gD4xcugJIziEbNNg2QWWtiFk/view?usp=sharing)

ðŸŒŸðŸ“Š Thank you for exploring the insights of this project. Should you have any questions or wish to discuss further, please feel free to reach out.
